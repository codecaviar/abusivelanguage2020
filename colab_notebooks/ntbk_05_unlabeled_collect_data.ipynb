{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"ntbk_04_unlabeled_collect_data.ipynb","provenance":[{"file_id":"16Dl07xpsSRvqcaiV07_p2h8S3tVIyVUE","timestamp":1619936899587}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"furnished-clearing"},"source":["# Dive into Abusive Language with Snorkel\n","\n","Author: BingYune Chen \n","<br>\n","Updated: 2021-08-02\n","<br><br>\n","Unlabeled Data is provided by [Twitter Archive](https://archive.org/details/twitterstream) \n","\n","----------"],"id":"furnished-clearing"},{"cell_type":"markdown","metadata":{"id":"90a93517"},"source":["We use the collection of JSON grabbed from the general Twitter stream. The data is from the \"Spritzer\" version of the stream, which includes the a light and shallow Twitter grab. The data is provided for the purposes of research, history, testing, and memory."],"id":"90a93517"},{"cell_type":"code","metadata":{"id":"UWs4w6dUtEJS"},"source":["# Imorts and setup for Google Colab \n","\n","# Mount Google Drive\n","from google.colab import drive ## module to use Google Drive with Python\n","drive.mount('/content/drive') ## mount to access contents\n","\n","# Install python libraries\n","! pip install spacy-langdetect --quiet\n","! pip install -U pip setuptools wheel --quiet\n","! pip install -U spacy --quiet\n","! python -m spacy download en_core_web_sm --quiet\n","## use 'en_core_web_trf' for slower, more accurate pipeline"],"id":"UWs4w6dUtEJS","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-mIZ6nREA8_T"},"source":["# Check GPU status on Google Colab\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"id":"-mIZ6nREA8_T","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Au8IceBwIxQ0"},"source":["# Download the compressed files for dates 2020 Jan to Jun (.tar)\n","for m in ['01', '02', '03', '04', '05', '06']: \n","## '01' - all, '02' - 10d, '03' - 12d, '04' - none, '05' - 7d, '06' - none\n","    for d in range(1, 31 + 1):\n","\n","        if d < 10:\n","            file_num = '0' + str(d)\n","        else:\n","            file_num = d\n","\n","        try:\n","            ! wget https://archive.org/download/archiveteam-twitter-stream-2020-{m}/twitter_stream_2020_{m}_{file_num}.tar\n","        except:\n","            pass\n"],"id":"Au8IceBwIxQ0","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjE5ccap9kiC"},"source":["# Unzip the compressed files for dates 2020 Jan to Jun (.tar)\n","for m in ['01', '02', '03', '04', '05', '06']: ## months\n","\n","    print('Starting month {}...'.format(m))\n","\n","    for d in range(1, 31 + 1): ## days 31 + 1\n","\n","        if d < 10:\n","            day_num = '0' + str(d)\n","        else:\n","            day_num = d\n","\n","        print('Starting day {}...'.format(day_num))\n","\n","        try:\n","            print('Extracting file...twitter_stream_2020_{}_{}.tar'.format(m, day_num))\n","\n","            temp_tar = tarfile.open('twitter_stream_2020_{}_{}.tar'.format(m, day_num))\n","            temp_tar.extractall('./2020_q1q2')\n","            temp_tar.close()\n","        except:\n","            pass"],"id":"kjE5ccap9kiC","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PRviaRR66oh"},"source":["# Download the compressed files for dates 2020 Jul to Dec (.zip)\n","for m in ['07', '08', '09', '10', '11', '12']: # all\n","\n","    for d in range(1, 31 + 1):\n","\n","        if d < 10:\n","            file_num = '0' + str(d)\n","        else:\n","            file_num = d\n","\n","        try:\n","            ! wget https://archive.org/download/archiveteam-twitter-stream-2020-{m}/twitter-stream-2020-{m}-{file_num}.zip\n","        except:\n","            pass"],"id":"2PRviaRR66oh","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgAysdGC9JMv"},"source":["# Unzip the compressed file for dates 2020 Jul to Dec (.zip)\n","for m in ['07', '08', '09', '10', '11', '12']: ## months \n","\n","    print('Starting month {}...'.format(m))\n","\n","    for d in range(1, 31 + 1): ## days 31 + 1\n","\n","        if d < 10:\n","            day_num = '0' + str(d)\n","        else:\n","            day_num = d\n","\n","        print('Starting day {}...'.format(day_num))\n","\n","        try:\n","            ! unzip twitter-stream-2020-{m}-{day_num}.zip\n","        except:\n","            pass"],"id":"AgAysdGC9JMv","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PL5nE7eZmSii"},"source":["# Read tar files\n","import tarfile\n","\n","# Imports for data and plotting\n","import pandas as pd\n","import numpy as np\n","\n","# Imports for spaCy preprocessing\n","from spacy_langdetect import LanguageDetector\n","from spacy.language import Language\n","import spacy\n","\n","nlp = spacy.load('en_core_web_sm')  \n","\n","def create_lang_detector(nlp, name):\n","    return LanguageDetector()\n","\n","Language.factory(\"language_detector\", func=create_lang_detector)\n","\n","nlp.add_pipe('language_detector', last=True) "],"id":"PL5nE7eZmSii","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLWUmvper_mb"},"source":["# Filter tweets for English for 2020-10-31 \n","for m in ['10']: ## months '07', '08', '09', '10', '11', '12' \n","\n","    print('Starting month {}...'.format(m))\n","\n","    for d in range(31, 32): ## days 31 + 1\n","\n","        if d < 10:\n","            day_num = '0' + str(d)\n","        else:\n","            day_num = d\n","\n","        print('Starting day {}...'.format(day_num))\n","\n","        try:\n","            \n","            for h in range(0, 24): ## hours 24\n","\n","                if h < 10:\n","                    hr_num = '0' + str(h)\n","                else:\n","                    hr_num = h\n","\n","                print('Starting hour {}...'.format(hr_num))\n","\n","                %cd SAVE_PATH ## add correct file path to zip files\n","\n","                for n in range(0, 60): ## minutes 60\n","\n","                    if n < 10:\n","                        min_num = '0' + str(n)\n","                    else:\n","                        min_num = n\n","\n","                    print('Starting minute {}...'.format(min_num))\n","\n","                    try:\n","                        ! bunzip2 -k {min_num}.json.bz2 \n","\n","                        hydrate_df = pd.read_json(\n","                            '{}.json'.format(min_num), lines=True\n","                            )\n","                        \n","                        hydrate_df['language'] = [\n","                            nlp(x)._.language['language'] for x in \n","                            hydrate_df.text.fillna(\" \") if x is not None\n","                        ]\n","\n","                        temp_df = hydrate_df.loc[\n","                            hydrate_df['language'] == 'en', ['text']\n","                            ]\n","                    \n","                        print('Saving file 2020{}{}_{}_{}...'.format(\n","                            m, day_num, hr_num, min_num\n","                            )\n","                        )\n","\n","                        temp_df.to_csv('2020{}{}_{}_{}.txt'.format(\n","                            m, day_num, hr_num, min_num\n","                            ), index=False\n","                        )\n","                    except:\n","                        pass\n","        except:\n","            pass"],"id":"oLWUmvper_mb","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtU4voMzmvPA"},"source":["# Filter tweets for English for 2020-11-01 to 2020-11-06 \n","for m in ['11']: ## months '07', '08', '09', '10', '11', '12' \n","\n","    print('Starting month {}...'.format(m))\n","\n","    for d in range(1, 7): ## days 31 + 1\n","\n","        if d < 10:\n","            day_num = '0' + str(d)\n","        else:\n","            day_num = d\n","\n","        print('Starting day {}...'.format(day_num))\n","\n","        try:\n","            \n","            for h in range(0, 24): ## hours 24\n","\n","                if h < 10:\n","                    hr_num = '0' + str(h)\n","                else:\n","                    hr_num = h\n","\n","                print('Starting hour {}...'.format(hr_num))\n","\n","                %cd SAVE_PATH ## add correct file path to zip files\n","\n","                for n in range(0, 60): ## minutes 60\n","\n","                    if n < 10:\n","                        min_num = '0' + str(n)\n","                    else:\n","                        min_num = n\n","\n","                    print('Starting minute {}...'.format(min_num))\n","\n","                    try:\n","                        ! bunzip2 -k {min_num}.json.bz2 \n","\n","                        hydrate_df = pd.read_json(\n","                            '{}.json'.format(min_num), lines=True\n","                            )\n","                        \n","                        hydrate_df['language'] = [\n","                            nlp(x)._.language['language'] for x in \n","                            hydrate_df.text.fillna(\" \") if x is not None\n","                        ]\n","\n","                        temp_df = hydrate_df.loc[\n","                            hydrate_df['language'] == 'en', ['text']\n","                            ]\n","                    \n","                        print('Saving file 2020{}{}_{}_{}...'.format(\n","                            m, day_num, hr_num, min_num\n","                            )\n","                        )\n","\n","                        temp_df.to_csv('2020{}{}_{}_{}.txt'.format(\n","                            m, day_num, hr_num, min_num\n","                            ), index=False\n","                        )\n","                    except:\n","                        pass\n","        except:\n","            pass"],"id":"BtU4voMzmvPA","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ngwi-7dUUPAR"},"source":[""],"id":"Ngwi-7dUUPAR","execution_count":null,"outputs":[]}]}