{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ntbk_01_labeled_collect_data.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNbluRo0ql3yO6rTU2Nhbzu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qXBhzbcpQaQV"},"source":["# Dive into Abusive Language with Snorkel\n","\n","Author: BingYune Chen \n","<br>\n","Updated: 2021-08-02\n","<br><br>\n","Labeled Data is provided by [University of Sheffield](https://github.com/ziqizhang/data) \n","\n","----------"]},{"cell_type":"markdown","metadata":{"id":"9RQQ-qDIAey3"},"source":["### Collection of Labeled Data\n","\n","With the help of Twitter API, we are able to recreate or \"rehydrate\" the original text for each tweet using tweet IDs provided in the labeled datasets.\n","\n","* Create developer account and register app\n","* Use consumer key and access token to access Twitter\n","\n","We define abusive language to include tweets that contain any text labeled as 'sexism,' 'racism,' or 'offensive' language by the original researchers.  "]},{"cell_type":"code","metadata":{"id":"GFPLaKiSoKCH"},"source":["# Imports and setup for Google Colab\n","\n","# Mount Google Drive\n","import os, sys ## interact with Google Drive's operating system\n","from google.colab import drive ## module to use Google Drive with Python\n","drive.mount('/content/drive') ## mount to access contents\n","\n","# Install python libraries\n","! pip install --target=$nb_path twarc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mPQlnFivaibN"},"source":["# Enter Twiitter API Access Information\n","CONSUMERKEY = ## API key (username)\n","CONSUMERSEECRET = ## API Secret Key (password)\n","ACCESSTOKEN = ## access token\n","ACCESSTOKENSECRET = ## access token secret "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OnbWE-sDQB8u"},"source":["# Use tweet IDs and Twitter API to hydrate tweets for labeled training data\n","# Recreate original dataset minus tweets deleted or removed from public view\n","# Twitter's Terms of Service allows users to only publish tweet IDs\n","\n","# Code adapted from Deen Freelon @UNC-Chapel-Hill \n","# >>> http://dfreelon.org/2017/01/03/beyond-the-hashtags-twitter-data/\n","\n","from twarc import Twarc \n","import json \n","\n","consumer_key = CONSUMERKEY ## API key (username)\n","consumer_secret = CONSUMERSECRET ## API Secret Key (password)\n","access_token = ACCESSTOKEN ## access token\n","access_token_secret = ACCESSTOKENSECRET ## access token secret \n","\n","t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)\n","data = []\n","\n","for tweet in t.hydrate(open('./data/raw/wz-l/labeled_data.csv')): ## training data\n","    data.append(json.dumps(tweet))\n","\n","with open('../data/interim/naacl_srw_2016_hydrate.json','w') as outfile:\n","    outfile.write(\"\\n\".join(data) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYcElzPWiBBW"},"source":["# Import standard libraries\n","import numpy as np\n","import pandas as pd\n","\n","import html"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eol59i8piB6-"},"source":["# Load hydrated, labeled data into pandas\n","label_df = pd.read_csv(\n","    '../data/raw/wz/NAACL_SRW_2016.csv', \n","    names=['tweet_id', 'class']\n","    )\n","hydrate_df = pd.read_json(\n","    '../data/interim/naacl_srw_2016_hydrate.json', \n","    lines=True\n","    )\n","merge_df = label_df.merge(hydrate_df, left_on='tweet_id', right_on='id')\n","\n","# Change to binary labels, 0 = no hate, 1 = hate\n","merge_df['label'] = merge_df['class'].map(\n","    {'none': 0, 'sexism': 1, 'racism': 1}\n","    ) \n","merge_df.rename(columns={'full_text': 'tweet'}, inplace=True)\n","\n","# Load hate and not hate data into pandas \n","twoclass_df = pd.read_csv(\n","    '../data/raw/dt/labeled_data_all_2classes_only.csv', \n","    usecols=['tweet', 'hate_speech', 'offensive_language']\n","    ) \n","# Include hate_speech and offensive language\n","twoclass_df['hate_count'] = (twoclass_df['hate_speech']\n","                             + twoclass_df['offensive_language']\n","                             )\n","twoclass_df['label'] = twoclass_df['hate_count'].apply(\n","    lambda x: 1 if x > 0 else x\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wHcpuW98iiLC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623545169699,"user_tz":420,"elapsed":330,"user":{"displayName":"BingYune Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9vmLT0W2zQ1nvJObMkPJzKm9UxHOOtvLXOr1g4g=s64","userId":"01631520334329415750"}},"outputId":"63d68cda-4c1d-4d51-c90f-b70d357e85b0"},"source":["# Combine datasets\n","pd.set_option('display.max_colwidth', None)\n","frames = [\n","          merge_df.loc[:,['label', 'tweet']], \n","          twoclass_df.loc[:,['label', 'tweet']]\n","]\n","df = pd.concat(frames, ignore_index=True)\n","df.label.value_counts() # 1: 24684, 0: 10637"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    24684\n","0    10637\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"vw720b0Lmyd9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623545171101,"user_tz":420,"elapsed":5,"user":{"displayName":"BingYune Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9vmLT0W2zQ1nvJObMkPJzKm9UxHOOtvLXOr1g4g=s64","userId":"01631520334329415750"}},"outputId":"d5774f68-2b49-47ce-9308-41b80c7404fd"},"source":["# Remove duplicates\n","df.sort_values(by='label', inplace=True)\n","df.drop_duplicates(subset='tweet', keep='first', inplace=True)\n","df.label.value_counts() # 1: 24604, 0: 10597"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    24604\n","0    10597\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Dj61e68Im9Ed"},"source":["# Reset index\n","df.reset_index(drop=True, inplace=True)\n","\n","# Unescape HTML elements\n","def unescape_html(tweet_txt):\n","    return html.unescape(tweet_txt)\n","\n","df['tweet'] = df['tweet'].apply(unescape_html)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghbPUc5M1enw"},"source":["# Save to csv\n","df.to_csv('../data/interim/labeled_combined_data.csv', index=False)\n","# Remove output error on rows 25571 and 25572"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ZIRm5o43A-z"},"source":[""],"execution_count":null,"outputs":[]}]}